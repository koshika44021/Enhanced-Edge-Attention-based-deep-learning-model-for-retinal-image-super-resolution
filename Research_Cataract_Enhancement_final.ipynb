{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-02T03:00:15.509991Z",
     "iopub.status.busy": "2024-05-02T03:00:15.509723Z",
     "iopub.status.idle": "2024-05-02T03:00:17.896082Z",
     "shell.execute_reply": "2024-05-02T03:00:17.89508Z",
     "shell.execute_reply.started": "2024-05-02T03:00:15.509967Z"
    },
    "id": "-Vr8lAAMKM9j",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7a433272-4e05-4014-c2fe-1cb828057a55",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('path to input data files'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:00:21.638449Z",
     "iopub.status.busy": "2024-05-02T03:00:21.637946Z",
     "iopub.status.idle": "2024-05-02T03:00:59.736905Z",
     "shell.execute_reply": "2024-05-02T03:00:59.735969Z",
     "shell.execute_reply.started": "2024-05-02T03:00:21.638417Z"
    },
    "id": "mAN91D8mKM9l",
    "outputId": "7adae906-3f2b-458e-ed4f-ea10929ec429",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths for your two image folders and the new combined folder\n",
    "folder1 = 'cataractdataset/dataset/1_normal'\n",
    "folder2 = 'cataractdataset//dataset/2_cataract'\n",
    "folder3 = 'cataractdataset//dataset/2_glaucoma'\n",
    "folder4 = 'cataractdataset//dataset/3_retina_disease'\n",
    "combined_folder = 'combined folder directory'\n",
    "\n",
    "# Create the combined folder if it doesn't exist\n",
    "if not os.path.exists(combined_folder):\n",
    "    os.makedirs(combined_folder)\n",
    "\n",
    "# Function to copy all files from a source to destination folder\n",
    "def copy_files(source_folder, destination_folder):\n",
    "    for filename in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "        # Check if file already exists in destination folder\n",
    "        if os.path.exists(destination_path):\n",
    "            # If yes, rename the file to avoid overwrite\n",
    "            basename, extension = os.path.splitext(filename)\n",
    "            new_filename = basename + '_copy' + extension\n",
    "            destination_path = os.path.join(destination_folder, new_filename)\n",
    "\n",
    "        # Copy file to destination folder\n",
    "        shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Copy images from both folders to the combined folder\n",
    "copy_files(folder1, combined_folder)\n",
    "copy_files(folder2, combined_folder)\n",
    "copy_files(folder3, combined_folder)\n",
    "copy_files(folder4, combined_folder)\n",
    "\n",
    "print(\"Images from both folders have been combined.\")\n",
    "runtime_records = {}\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:00:59.739488Z",
     "iopub.status.busy": "2024-05-02T03:00:59.738814Z",
     "iopub.status.idle": "2024-05-02T03:03:03.106446Z",
     "shell.execute_reply": "2024-05-02T03:03:03.105544Z",
     "shell.execute_reply.started": "2024-05-02T03:00:59.739451Z"
    },
    "id": "oYq51qCuKM9m",
    "outputId": "cdff8b7d-add7-4c1b-acfd-b14735f1440c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Function to load and process images from the combined dataset directory\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(img_path):  # Check if the item is a file\n",
    "            img = load_img(img_path, target_size=(128, 128))  # Resize to 128x128\n",
    "            img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Load combined dataset\n",
    "combined_dataset = load_images('combined folder directory')  # Update this path to your combined dataset directory\n",
    "\n",
    "# Split dataset into training and testing\n",
    "train_images, test_images = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data preparation function\n",
    "def build_data(image):\n",
    "    lr = tf.image.resize(image, (64, 64))\n",
    "    lr = tf.image.resize(lr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return (lr, image)\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).map(build_data).batch(32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).map(build_data).batch(32)\n",
    "\n",
    "# SRCNN Model\n",
    "SRCNN_915 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 9, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 7, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(3, 5, padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "SRCNN_915.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "SRCNN_915.fit(train_data, epochs=10, validation_data=test_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "runtime_records[\"SRCNN Original\"] = runtime\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:03:03.1083Z",
     "iopub.status.busy": "2024-05-02T03:03:03.107716Z",
     "iopub.status.idle": "2024-05-02T03:03:06.859133Z",
     "shell.execute_reply": "2024-05-02T03:03:06.858201Z",
     "shell.execute_reply.started": "2024-05-02T03:03:03.108271Z"
    },
    "id": "1DcYOP8hKM9n",
    "outputId": "e8baa9e3-2298-4134-edba-28f3f65b52dd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to display test images and their super-resolved versio\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure  # For SSIM calculation\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from scipy.ndimage import sobel  # For sharpness calculation\n",
    "\n",
    "def display_test_images(test_data, model):\n",
    "    for lr, hr in test_data.take(5):\n",
    "        # Generate super-resolved (SR) image from low-resolution (LR) input\n",
    "        sr = model.predict(lr[np.newaxis, ...])\n",
    "\n",
    "        # Ensure lr, hr, and sr[0] are NumPy arrays\n",
    "        lr_np = lr.numpy() if isinstance(lr, tf.Tensor) else lr\n",
    "        hr_np = hr.numpy() if isinstance(hr, tf.Tensor) else hr\n",
    "        sr_np = sr[0].numpy() if isinstance(sr[0], tf.Tensor) else sr[0]\n",
    "\n",
    "        # Calculate PSNR values\n",
    "        psnr_lr_hr = tf.image.psnr(lr, hr, max_val=1.0).numpy()\n",
    "        psnr_sr_hr = tf.image.psnr(sr[0], hr, max_val=1.0).numpy()\n",
    "\n",
    "        # Calculate SSIM values\n",
    "        # Calculate SSIM values with a smaller window size\n",
    "        ssim_lr_hr = ssim(lr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "        ssim_sr_hr = ssim(sr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "\n",
    "        # Calculate sharpness difference\n",
    "        def calc_sharpness(image):\n",
    "            gx = sobel(image, axis=0)\n",
    "            gy = sobel(image, axis=1)\n",
    "            return np.sqrt(gx**2 + gy**2).mean()\n",
    "\n",
    "        sharpness_hr = calc_sharpness(hr_np)\n",
    "        sharpness_sr = calc_sharpness(sr_np)\n",
    "        sharpness_difference = sharpness_sr - sharpness_hr\n",
    "\n",
    "        # Plot LR, SR, and HR images along with their metrics\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f'Low Resolution\\nPSNR: {psnr_lr_hr:.2f} dB\\nSSIM: {ssim_lr_hr:.2f}')\n",
    "        plt.imshow(lr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f'Super Resolution\\nPSNR: {psnr_sr_hr:.2f} dB\\nSSIM: {ssim_sr_hr:.2f}\\nSharpness Diff: {sharpness_difference:.2f}')\n",
    "        plt.imshow(sr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Original Resolution')\n",
    "        plt.imshow(hr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    return psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr\n",
    "\n",
    "# Display some test images and their super-resolved versions along with the metrics\n",
    "psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr = display_test_images(test_data.unbatch(), SRCNN_915)\n",
    "metrics[\"SRCNN\"] = [psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:04:20.124729Z",
     "iopub.status.busy": "2024-05-02T03:04:20.124444Z",
     "iopub.status.idle": "2024-05-02T03:05:45.331013Z",
     "shell.execute_reply": "2024-05-02T03:05:45.330029Z",
     "shell.execute_reply.started": "2024-05-02T03:04:20.124705Z"
    },
    "id": "RYDDStGKKM9r",
    "outputId": "c5d47c3b-5a3d-41ab-bc1b-58177b54dd57",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Edge Loss Function\n",
    "def edge_loss(y_true, y_pred):\n",
    "    sobel_x = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32)\n",
    "    sobel_x_filter = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
    "    sobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n",
    "\n",
    "    # Apply filters to each channel separately\n",
    "    def apply_filters(images):\n",
    "        channels = tf.split(images, num_or_size_splits=3, axis=-1)  # Split the images into channels\n",
    "        edge_images = []\n",
    "        for channel in channels:\n",
    "            edge_x = tf.nn.conv2d(channel, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge_y = tf.nn.conv2d(channel, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#             edge = tf.sqrt(tf.square(edge_x) + tf.square(edge_y))\n",
    "            edge = tf.sqrt(tf.square(edge_x) + tf.square(edge_y) + 1e-12)  # Adding a small epsilon value for numerical stability\n",
    "\n",
    "            edge_images.append(edge)\n",
    "        return tf.concat(edge_images, axis=-1)  # Combine edge information from all channels\n",
    "\n",
    "    edges_true = apply_filters(y_true)\n",
    "    edges_pred = apply_filters(y_pred)\n",
    "\n",
    "    return tf.reduce_mean(tf.abs(edges_pred - edges_true))\n",
    "\n",
    "\n",
    "# Combined Loss Function\n",
    "def combined_loss(y_true, y_pred):\n",
    "    alpha = 0.5  # Adjust the weight of edge loss as needed\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred) + alpha * edge_loss(y_true, y_pred)\n",
    "\n",
    "# Function to load and process images\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load dataset and split\n",
    "combined_dataset = load_images('combined folder directory')\n",
    "train_images, test_images = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data preparation function\n",
    "def build_data(image):\n",
    "    lr = tf.image.resize(image, (64, 64))\n",
    "    lr = tf.image.resize(lr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return (lr, image)\n",
    "\n",
    "# Prepare datasets\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).map(build_data).batch(32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).map(build_data).batch(32)\n",
    "\n",
    "\n",
    "SRCNN_915 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),  # Additional layer for capturing more details\n",
    "    tf.keras.layers.Conv2D(3, 3, padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with the combined loss\n",
    "SRCNN_915.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "SRCNN_915.fit(train_data, epochs=10, validation_data=test_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "runtime_records[\"SRCNN_915\"] = runtime\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:05:45.332552Z",
     "iopub.status.busy": "2024-05-02T03:05:45.332277Z",
     "iopub.status.idle": "2024-05-02T03:05:48.371208Z",
     "shell.execute_reply": "2024-05-02T03:05:48.370246Z",
     "shell.execute_reply.started": "2024-05-02T03:05:45.332528Z"
    },
    "id": "r3SoNPmlKM9s",
    "outputId": "89896895-90df-4d12-f521-4beb7bd7016d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure  # For SSIM calculation\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from scipy.ndimage import sobel  # For sharpness calculation\n",
    "\n",
    "def display_test_images(test_data, model):\n",
    "    for lr, hr in test_data.take(5):\n",
    "        # Generate super-resolved (SR) image from low-resolution (LR) input\n",
    "        sr = model.predict(lr[np.newaxis, ...])\n",
    "\n",
    "        # Ensure lr, hr, and sr[0] are NumPy arrays\n",
    "        lr_np = lr.numpy() if isinstance(lr, tf.Tensor) else lr\n",
    "        hr_np = hr.numpy() if isinstance(hr, tf.Tensor) else hr\n",
    "        sr_np = sr[0].numpy() if isinstance(sr[0], tf.Tensor) else sr[0]\n",
    "\n",
    "        # Calculate PSNR values\n",
    "        psnr_lr_hr = tf.image.psnr(lr, hr, max_val=1.0).numpy()\n",
    "        psnr_sr_hr = tf.image.psnr(sr[0], hr, max_val=1.0).numpy()\n",
    "\n",
    "        # Calculate SSIM values\n",
    "        # Calculate SSIM values with a smaller window size\n",
    "        ssim_lr_hr = ssim(lr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "        ssim_sr_hr = ssim(sr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "\n",
    "        # Calculate sharpness difference\n",
    "        def calc_sharpness(image):\n",
    "            gx = sobel(image, axis=0)\n",
    "            gy = sobel(image, axis=1)\n",
    "            return np.sqrt(gx**2 + gy**2).mean()\n",
    "\n",
    "        sharpness_hr = calc_sharpness(hr_np)\n",
    "        sharpness_sr = calc_sharpness(sr_np)\n",
    "        sharpness_difference = sharpness_sr - sharpness_hr\n",
    "\n",
    "        # Plot LR, SR, and HR images along with their metrics\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f'Low Resolution\\nPSNR: {psnr_lr_hr:.2f} dB\\nSSIM: {ssim_lr_hr:.2f}')\n",
    "        plt.imshow(lr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f'Super Resolution\\nPSNR: {psnr_sr_hr:.2f} dB\\nSSIM: {ssim_sr_hr:.2f}\\nSharpness Diff: {sharpness_difference:.2f}')\n",
    "        plt.imshow(sr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Original Resolution')\n",
    "        plt.imshow(hr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    return psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr\n",
    "\n",
    "# Display some test images and their super-resolved versions along with the metrics\n",
    "psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr = display_test_images(test_data.unbatch(), SRCNN_915_modified)\n",
    "metrics[\"SRCNN Edge Loss\"] = [psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:05:48.37288Z",
     "iopub.status.busy": "2024-05-02T03:05:48.37259Z",
     "iopub.status.idle": "2024-05-02T03:06:57.488768Z",
     "shell.execute_reply": "2024-05-02T03:06:57.487806Z",
     "shell.execute_reply.started": "2024-05-02T03:05:48.372856Z"
    },
    "id": "qyH0NmsUKM9u",
    "outputId": "104d0b29-0196-4862-89d1-eaec405848da",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Edge Loss Function\n",
    "def edge_loss(y_true, y_pred):\n",
    "    sobel_x = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32)\n",
    "    sobel_x_filter = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
    "    sobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n",
    "\n",
    "    # Apply filters to each channel separately\n",
    "    def apply_filters(images):\n",
    "        channels = tf.split(images, num_or_size_splits=3, axis=-1)\n",
    "        edge_images = []\n",
    "        for channel in channels:\n",
    "            edge_x = tf.nn.conv2d(channel, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge_y = tf.nn.conv2d(channel, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge = tf.sqrt(tf.square(edge_x) + tf.square(edge_y) + 1e-12)\n",
    "            edge_images.append(edge)\n",
    "        return tf.concat(edge_images, axis=-1)\n",
    "\n",
    "    edges_true = apply_filters(y_true)\n",
    "    edges_pred = apply_filters(y_pred)\n",
    "\n",
    "    return tf.reduce_mean(tf.abs(edges_pred - edges_true))\n",
    "\n",
    "# Combined Loss Function\n",
    "def combined_loss(y_true, y_pred):\n",
    "    alpha = 0.5  # Adjust the weight of edge loss as needed\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred) + alpha * edge_loss(y_true, y_pred)\n",
    "\n",
    "# Custom Sharpening Layer\n",
    "class SharpeningLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SharpeningLayer, self).__init__()\n",
    "        self.sharpening_kernel = tf.constant([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=tf.float32)\n",
    "        self.sharpening_kernel = self.sharpening_kernel[:, :, tf.newaxis, tf.newaxis]\n",
    "        self.sharpening_kernel = tf.tile(self.sharpening_kernel, [1, 1, 3, 1])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depthwise_conv2d(inputs, self.sharpening_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Function to load and process images\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load dataset and split\n",
    "combined_dataset = load_images('combined folder directory')  # Update the path as per your dataset location\n",
    "train_images, test_images = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data preparation function\n",
    "def build_data(image):\n",
    "    lr = tf.image.resize(image, (64, 64))\n",
    "    lr = tf.image.resize(lr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return (lr, image)\n",
    "\n",
    "# Prepare datasets\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).map(build_data).batch(32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).map(build_data).batch(32)\n",
    "\n",
    "# Modified SRCNN Model with smaller kernel sizes and a sharpening layer at the end\n",
    "SRCNN_sharpening = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),  # Additional layer for capturing more details\n",
    "    tf.keras.layers.Conv2D(3, 3, padding='same'),\n",
    "    SharpeningLayer()  # Custom sharpening layer\n",
    "])\n",
    "\n",
    "# Compile the model with the combined loss\n",
    "SRCNN_sharpening.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "SRCNN_sharpening.fit(train_data, epochs=10, validation_data=test_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "runtime_records[\"SRCNN Sharpening\"] = runtime\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:06:57.490824Z",
     "iopub.status.busy": "2024-05-02T03:06:57.490064Z",
     "iopub.status.idle": "2024-05-02T03:06:59.890529Z",
     "shell.execute_reply": "2024-05-02T03:06:59.88957Z",
     "shell.execute_reply.started": "2024-05-02T03:06:57.490796Z"
    },
    "id": "sgLWb_2qKM9v",
    "outputId": "4e5242f1-c68f-4a6f-cb35-ea7b4d5bbe6a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure  # For SSIM calculation\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from scipy.ndimage import sobel  # For sharpness calculation\n",
    "\n",
    "def display_test_images(test_data, model):\n",
    "    for lr, hr in test_data.take(5):\n",
    "        # Generate super-resolved (SR) image from low-resolution (LR) input\n",
    "        sr = model.predict(lr[np.newaxis, ...])\n",
    "\n",
    "        # Ensure lr, hr, and sr[0] are NumPy arrays\n",
    "        lr_np = lr.numpy() if isinstance(lr, tf.Tensor) else lr\n",
    "        hr_np = hr.numpy() if isinstance(hr, tf.Tensor) else hr\n",
    "        sr_np = sr[0].numpy() if isinstance(sr[0], tf.Tensor) else sr[0]\n",
    "\n",
    "        # Calculate PSNR values\n",
    "        psnr_lr_hr = tf.image.psnr(lr, hr, max_val=1.0).numpy()\n",
    "        psnr_sr_hr = tf.image.psnr(sr[0], hr, max_val=1.0).numpy()\n",
    "\n",
    "        # Calculate SSIM values\n",
    "        # Calculate SSIM values with a smaller window size\n",
    "        ssim_lr_hr = ssim(lr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "        ssim_sr_hr = ssim(sr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "\n",
    "        # Calculate sharpness difference\n",
    "        def calc_sharpness(image):\n",
    "            gx = sobel(image, axis=0)\n",
    "            gy = sobel(image, axis=1)\n",
    "            return np.sqrt(gx**2 + gy**2).mean()\n",
    "\n",
    "        sharpness_hr = calc_sharpness(hr_np)\n",
    "        sharpness_sr = calc_sharpness(sr_np)\n",
    "        sharpness_difference = sharpness_sr - sharpness_hr\n",
    "\n",
    "        # Plot LR, SR, and HR images along with their metrics\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f'Low Resolution\\nPSNR: {psnr_lr_hr:.2f} dB\\nSSIM: {ssim_lr_hr:.2f}')\n",
    "        plt.imshow(lr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f'Super Resolution\\nPSNR: {psnr_sr_hr:.2f} dB\\nSSIM: {ssim_sr_hr:.2f}\\nSharpness Diff: {sharpness_difference:.2f}')\n",
    "        plt.imshow(sr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Original Resolution')\n",
    "        plt.imshow(hr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    return psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr\n",
    "\n",
    "# Display some test images and their super-resolved versions along with the metrics\n",
    "psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr = display_test_images(test_data.unbatch(), SRCNN_915_modified_with_sharpening)\n",
    "metrics[\"SRCNN Sharpening\"] = [psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:06:59.894552Z",
     "iopub.status.busy": "2024-05-02T03:06:59.894251Z",
     "iopub.status.idle": "2024-05-02T03:08:45.499638Z",
     "shell.execute_reply": "2024-05-02T03:08:45.498689Z",
     "shell.execute_reply.started": "2024-05-02T03:06:59.894527Z"
    },
    "id": "gJSMpCrkKM9w",
    "outputId": "9c2b644b-a665-4880-f9ee-51a24ed2daba",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "# Edge Loss Function\n",
    "def edge_loss(y_true, y_pred):\n",
    "    sobel_x = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32)\n",
    "    sobel_x_filter = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
    "    sobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n",
    "\n",
    "    def apply_filters(images):\n",
    "        channels = tf.split(images, num_or_size_splits=3, axis=-1)\n",
    "        edge_images = []\n",
    "        for channel in channels:\n",
    "            edge_x = tf.nn.conv2d(channel, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge_y = tf.nn.conv2d(channel, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge = tf.sqrt(tf.square(edge_x) + tf.square(edge_y) + 1e-12)\n",
    "            edge_images.append(edge)\n",
    "        return tf.concat(edge_images, axis=-1)\n",
    "\n",
    "    edges_true = apply_filters(y_true)\n",
    "    edges_pred = apply_filters(y_pred)\n",
    "\n",
    "    return tf.reduce_mean(tf.abs(edges_pred - edges_true))\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    alpha = 0.5  # Adjust the weight of edge loss as needed\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred) + alpha * edge_loss(y_true, y_pred)\n",
    "\n",
    "class SharpeningLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SharpeningLayer, self).__init__()\n",
    "        self.sharpening_kernel = tf.constant([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=tf.float32)\n",
    "        self.sharpening_kernel = self.sharpening_kernel[:, :, tf.newaxis, tf.newaxis]\n",
    "        self.sharpening_kernel = tf.tile(self.sharpening_kernel, [1, 1, 3, 1])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depthwise_conv2d(inputs, self.sharpening_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "class ChannelAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction_ratio=16):\n",
    "        super(ChannelAttentionLayer, self).__init__()\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense1 = tf.keras.layers.Dense(input_shape[-1] // self.reduction_ratio, activation='relu', use_bias=False)\n",
    "        self.dense2 = tf.keras.layers.Dense(input_shape[-1], activation='sigmoid', use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gap = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        channel_wise_interaction = self.dense1(gap)\n",
    "        scale = self.dense2(channel_wise_interaction)\n",
    "        return inputs * scale\n",
    "\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "combined_dataset = load_images('combined folder directory')  # Update the path as per your dataset location\n",
    "train_images, test_images = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_data(image):\n",
    "    lr = tf.image.resize(image, (64, 64))\n",
    "    lr = tf.image.resize(lr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return (lr, image)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).map(build_data).batch(32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).map(build_data).batch(32)\n",
    "\n",
    "# Modified SRCNN Model with Channel Attention and a sharpening layer at the end\n",
    "SRCNN_attention = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    ChannelAttentionLayer(),  # Channel Attention after the first convolutional layer\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    ChannelAttentionLayer(),  # Channel Attention after the second convolutional layer\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    ChannelAttentionLayer(),  # Channel Attention after the third convolutional layer\n",
    "    tf.keras.layers.Conv2D(3, 3, padding='same'),\n",
    "    SharpeningLayer()  # Custom sharpening layer\n",
    "])\n",
    "\n",
    "SRCNN_attention.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1, write_graph=True)\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "SRCNN_attention.fit(train_data, epochs=50, validation_data=test_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "runtime_records[\"ESRCNN\"] = runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:08:45.501353Z",
     "iopub.status.busy": "2024-05-02T03:08:45.500969Z",
     "iopub.status.idle": "2024-05-02T03:08:48.058809Z",
     "shell.execute_reply": "2024-05-02T03:08:48.057823Z",
     "shell.execute_reply.started": "2024-05-02T03:08:45.50132Z"
    },
    "id": "jJfMvG4zKM9w",
    "outputId": "5b1f105c-49e5-4dce-c728-d8ab2ca2263e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# plot_path = 'model_architecture.png'\n",
    "# plot_model(SRCNN_915_with_attention, to_file=plot_path, show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure  # For SSIM calculation\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from scipy.ndimage import sobel  # For sharpness calculation\n",
    "\n",
    "def display_test_images(test_data, model):\n",
    "    for lr, hr in test_data.take(5):\n",
    "        # Generate super-resolved (SR) image from low-resolution (LR) input\n",
    "        sr = model.predict(lr[np.newaxis, ...])\n",
    "\n",
    "        # Ensure lr, hr, and sr[0] are NumPy arrays\n",
    "        lr_np = lr.numpy() if isinstance(lr, tf.Tensor) else lr\n",
    "        hr_np = hr.numpy() if isinstance(hr, tf.Tensor) else hr\n",
    "        sr_np = sr[0].numpy() if isinstance(sr[0], tf.Tensor) else sr[0]\n",
    "\n",
    "        # Calculate PSNR values\n",
    "        psnr_lr_hr = tf.image.psnr(lr, hr, max_val=1.0).numpy()\n",
    "        psnr_sr_hr = tf.image.psnr(sr[0], hr, max_val=1.0).numpy()\n",
    "\n",
    "        # Calculate SSIM values\n",
    "        # Calculate SSIM values with a smaller window size\n",
    "        ssim_lr_hr = ssim(lr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "        ssim_sr_hr = ssim(sr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "\n",
    "        # Calculate sharpness difference\n",
    "        def calc_sharpness(image):\n",
    "            gx = sobel(image, axis=0)\n",
    "            gy = sobel(image, axis=1)\n",
    "            return np.sqrt(gx**2 + gy**2).mean()\n",
    "\n",
    "        sharpness_hr = calc_sharpness(hr_np)\n",
    "        sharpness_sr = calc_sharpness(sr_np)\n",
    "        sharpness_difference = sharpness_sr - sharpness_hr\n",
    "\n",
    "        # Plot LR, SR, and HR images along with their metrics\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f'Low Resolution\\nPSNR: {psnr_lr_hr:.2f} dB\\nSSIM: {ssim_lr_hr:.2f}')\n",
    "        plt.imshow(lr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f'Super Resolution\\nPSNR: {psnr_sr_hr:.2f} dB\\nSSIM: {ssim_sr_hr:.2f}\\nSharpness Diff: {sharpness_difference:.2f}')\n",
    "        plt.imshow(sr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Original Resolution')\n",
    "        plt.imshow(hr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    return psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr\n",
    "\n",
    "# Display some test images and their super-resolved versions along with the metrics\n",
    "psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr = display_test_images(test_data.unbatch(), SRCNN_915_with_attention)\n",
    "metrics[\"ESRCNN\"] = [psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:08:48.060461Z",
     "iopub.status.busy": "2024-05-02T03:08:48.060133Z",
     "iopub.status.idle": "2024-05-02T03:11:59.350329Z",
     "shell.execute_reply": "2024-05-02T03:11:59.34939Z",
     "shell.execute_reply.started": "2024-05-02T03:08:48.060436Z"
    },
    "id": "IOSuJG3wKM9x",
    "outputId": "814e709b-9763-4d61-fe19-d53c9e07da4b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Edge Loss Function\n",
    "def edge_loss(y_true, y_pred):\n",
    "    sobel_x = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32)\n",
    "    sobel_x_filter = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
    "    sobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n",
    "    def apply_filters(images):\n",
    "        channels = tf.split(images, num_or_size_splits=3, axis=-1)\n",
    "        edge_images = []\n",
    "        for channel in channels:\n",
    "            edge_x = tf.nn.conv2d(channel, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge_y = tf.nn.conv2d(channel, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge = tf.sqrt(tf.square(edge_x) + tf.square(edge_y) + 1e-12)\n",
    "            edge_images.append(edge)\n",
    "        return tf.concat(edge_images, axis=-1)\n",
    "    edges_true = apply_filters(y_true)\n",
    "    edges_pred = apply_filters(y_pred)\n",
    "    return tf.reduce_mean(tf.abs(edges_pred - edges_true))\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_pred_resized = tf.image.resize(y_pred, (tf.shape(y_true)[1], tf.shape(y_true)[2]), method='bilinear')\n",
    "    alpha = 0.9\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred_resized) + alpha * edge_loss(y_true, y_pred_resized)\n",
    "\n",
    "# Sharpening Layer\n",
    "class SharpeningLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SharpeningLayer, self).__init__()\n",
    "        self.sharpening_kernel = tf.constant([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=tf.float32)\n",
    "        self.sharpening_kernel = self.sharpening_kernel[:, :, tf.newaxis, tf.newaxis]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Ensure the kernel matches the number of input channels\n",
    "        num_channels = input_shape[-1]\n",
    "        self.sharpening_kernel = tf.tile(self.sharpening_kernel, [1, 1, num_channels, 1])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depthwise_conv2d(inputs, self.sharpening_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Channel Attention Layer\n",
    "class ChannelAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction_ratio=16):\n",
    "        super(ChannelAttentionLayer, self).__init__()\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense1 = tf.keras.layers.Dense(input_shape[-1] // self.reduction_ratio, activation='relu', use_bias=False)\n",
    "        self.dense2 = tf.keras.layers.Dense(input_shape[-1], activation='sigmoid', use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gap = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        channel_wise_interaction = self.dense1(gap)\n",
    "        scale = self.dense2(channel_wise_interaction)\n",
    "        return inputs * scale\n",
    "\n",
    "# Spatial Attention Layer\n",
    "class SpatialAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttentionLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Define Conv2D layer here to ensure it's created only once\n",
    "        self.conv = tf.keras.layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "        concat = tf.concat([avg_pool, max_pool], axis=-1)\n",
    "        # Use the previously defined Conv2D layer\n",
    "        filters = self.conv(concat)\n",
    "        return inputs * filters\n",
    "\n",
    "\n",
    "class SubpixelConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, scale=2, **kwargs):\n",
    "        super(SubpixelConv2D, self).__init__(**kwargs)\n",
    "        self.scale = scale  # Ensure scale is correctly set for upscaling\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # This layer will only be used for upscaling with valid scale factors\n",
    "        if self.scale > 1:\n",
    "            return tf.nn.depth_to_space(inputs, self.scale)\n",
    "        else:\n",
    "            raise ValueError(\"Scale factor must be greater than 1 for SubpixelConv2D\")\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.scale > 1:\n",
    "            return (input_shape[0], input_shape[1] * self.scale, input_shape[2] * self.scale, input_shape[3] // (self.scale ** 2))\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "combined_dataset = load_images('combined folder directory')  # Update the path as per your dataset location\n",
    "train_images, test_images = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_data(image):\n",
    "    lr = tf.image.resize(image, (64, 64))\n",
    "    lr = tf.image.resize(lr, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return (lr, image)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).map(build_data).batch(32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).map(build_data).batch(32)\n",
    "\n",
    "\n",
    "SRCNN_915_with_attention = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    ChannelAttentionLayer(reduction_ratio=16),  # Channel attention after the first convolution\n",
    "    SpatialAttentionLayer(),  # Spatial attention added here\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    SharpeningLayer(),  # Sharpening layer added here\n",
    "    SubpixelConv2D(scale=2),  # Upscaling to 256x256\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    ChannelAttentionLayer(reduction_ratio=16),\n",
    "    tf.keras.layers.Conv2D(3, 3, padding='same', activation='relu'),  # Final output with correct dimensions\n",
    "    tf.keras.layers.Resizing(128, 128)  # Resize back to original dimensions\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SRCNN_915_with_attention.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1, write_graph=True)\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "SRCNN_915_with_attention.fit(train_data, epochs=50, validation_data=test_data, callbacks=[tensorboard_callback])\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f\"Training runtime: {runtime} seconds\")\n",
    "runtime_records[\"EEASRCNN\"] = runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:11:59.351797Z",
     "iopub.status.busy": "2024-05-02T03:11:59.351507Z",
     "iopub.status.idle": "2024-05-02T03:12:03.115095Z",
     "shell.execute_reply": "2024-05-02T03:12:03.114156Z",
     "shell.execute_reply.started": "2024-05-02T03:11:59.351772Z"
    },
    "id": "6O2Pf4UyKM9y",
    "outputId": "12948cbe-d3b4-4423-dc9c-7f4bbb0690de",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure  # For SSIM calculation\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from scipy.ndimage import sobel  # For sharpness calculation\n",
    "\n",
    "def display_test_images(test_data, model):\n",
    "    for lr, hr in test_data.take(5):\n",
    "        # Generate super-resolved (SR) image from low-resolution (LR) input\n",
    "        sr = model.predict(lr[np.newaxis, ...])\n",
    "\n",
    "        # Ensure lr, hr, and sr[0] are NumPy arrays\n",
    "        lr_np = lr.numpy() if isinstance(lr, tf.Tensor) else lr\n",
    "        hr_np = hr.numpy() if isinstance(hr, tf.Tensor) else hr\n",
    "        sr_np = sr[0].numpy() if isinstance(sr[0], tf.Tensor) else sr[0]\n",
    "\n",
    "        # Calculate PSNR values\n",
    "        psnr_lr_hr = tf.image.psnr(lr, hr, max_val=1.0).numpy()\n",
    "        psnr_sr_hr = tf.image.psnr(sr[0], hr, max_val=1.0).numpy()\n",
    "\n",
    "        # Calculate SSIM values\n",
    "        # Calculate SSIM values with a smaller window size\n",
    "        ssim_lr_hr = ssim(lr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "        ssim_sr_hr = ssim(sr_np, hr_np, data_range=hr_np.max() - hr_np.min(), multichannel=True, win_size=3)\n",
    "\n",
    "        # Calculate sharpness difference\n",
    "        def calc_sharpness(image):\n",
    "            gx = sobel(image, axis=0)\n",
    "            gy = sobel(image, axis=1)\n",
    "            return np.sqrt(gx**2 + gy**2).mean()\n",
    "\n",
    "        sharpness_hr = calc_sharpness(hr_np)\n",
    "        sharpness_sr = calc_sharpness(sr_np)\n",
    "        sharpness_difference = sharpness_sr - sharpness_hr\n",
    "\n",
    "        # Plot LR, SR, and HR images along with their metrics\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f'Low Resolution\\nPSNR: {psnr_lr_hr:.2f} dB\\nSSIM: {ssim_lr_hr:.2f}')\n",
    "        plt.imshow(lr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f'Super Resolution\\nPSNR: {psnr_sr_hr:.2f} dB\\nSSIM: {ssim_sr_hr:.2f}\\nSharpness Diff: {sharpness_difference:.2f}')\n",
    "        plt.imshow(sr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Original Resolution')\n",
    "        plt.imshow(hr_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    return psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr\n",
    "\n",
    "# Display some test images and their super-resolved versions along with the metrics\n",
    "psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr = display_test_images(test_data.unbatch(), SRCNN_915_with_attention)\n",
    "metrics[\"EEASRCNN\"] = [psnr_lr_hr, psnr_sr_hr, ssim_lr_hr, ssim_sr_hr, sharpness_hr, sharpness_sr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:12:03.116681Z",
     "iopub.status.busy": "2024-05-02T03:12:03.116376Z",
     "iopub.status.idle": "2024-05-02T03:12:03.367629Z",
     "shell.execute_reply": "2024-05-02T03:12:03.366696Z",
     "shell.execute_reply.started": "2024-05-02T03:12:03.116655Z"
    },
    "id": "aK4rz2YDKM9y",
    "outputId": "72d6a6c0-b4c2-4e54-b78d-df6cde15c577",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Extracting names and runtime values\n",
    "names = list(runtime_records.keys())\n",
    "values = list(runtime_records.values())\n",
    "\n",
    "# Creating the bar plot\n",
    "plt.figure(figsize=(10, 6))  # You can adjust the figure size as needed\n",
    "plt.bar(names, values, color='skyblue')  # You can change the color\n",
    "\n",
    "plt.xlabel('Algorithm')  # X-axis label\n",
    "plt.ylabel('Runtime (ms)')  # Y-axis label\n",
    "plt.title('Runtime Measures of Algorithms')  # Plot title\n",
    "plt.xticks(rotation=45)  # Rotate names for better readability if necessary\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Adding a grid for better readability; customize as needed\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:13:19.968985Z",
     "iopub.status.busy": "2024-05-02T03:13:19.968631Z",
     "iopub.status.idle": "2024-05-02T03:13:19.992087Z",
     "shell.execute_reply": "2024-05-02T03:13:19.990993Z",
     "shell.execute_reply.started": "2024-05-02T03:13:19.968958Z"
    },
    "id": "MTSrM5xzKM9z",
    "outputId": "ea97073e-9439-4bd6-9c72-249c5ccb4daa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the column names for your metrics\n",
    "columns = ['PSNR LR-HR', 'PSNR SR-HR', 'SSIM LR-HR', 'SSIM SR-HR', 'Sharpness HR', 'Sharpness SR']\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index', columns=columns)\n",
    "\n",
    "# Reset index to add the model names as a separate column\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T03:12:03.422185Z",
     "iopub.status.busy": "2024-05-02T03:12:03.421536Z",
     "iopub.status.idle": "2024-05-02T03:12:03.893779Z",
     "shell.execute_reply": "2024-05-02T03:12:03.892787Z",
     "shell.execute_reply.started": "2024-05-02T03:12:03.422134Z"
    },
    "id": "Wqdg7WvsKM9z",
    "outputId": "669500e6-75ed-44fe-d702-be27877544be",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Metrics names for labeling the plot\n",
    "metric_names = ['PSNR LR-HR', 'PSNR SR-HR', 'SSIM LR-HR', 'SSIM SR-HR', 'Sharpness HR', 'Sharpness SR']\n",
    "\n",
    "# Number of models and metrics\n",
    "num_models = len(metrics)\n",
    "num_metrics = len(metric_names)\n",
    "\n",
    "# Create a 2D array from the metrics dictionary\n",
    "data = np.array([metrics[model] for model in metrics])\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(num_models)\n",
    "bar_width = 0.1  # Adjust as necessary for clarity\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(num_metrics):\n",
    "    plt.bar(positions + i * bar_width, data[:, i], width=bar_width, label=metric_names[i])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Metric Values')\n",
    "plt.title('Comparison of Different Metrics Across Models')\n",
    "plt.xticks(positions + bar_width * (num_metrics - 1) / 2, metrics.keys())\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajVtTeptKM9z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBMAHqtcKM9z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyrvd8tQKM9z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABxKxgqRKM90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpUPggc-KM90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykQitsPmKM90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6-tm4HPKM90"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 314116,
     "sourceId": 636067,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
